<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>记录是为了更好的创造</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="记录是为了更好的创造">
<meta property="og:url" content="https://linsheng9731.github.io/page/6/index.html">
<meta property="og:site_name" content="记录是为了更好的创造">
<meta property="og:locale" content="zh">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="记录是为了更好的创造">
  
    <link rel="alternate" href="/atom.xml" title="记录是为了更好的创造" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">记录是为了更好的创造</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://linsheng9731.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-e4-ba-92-e8-81-94-e7-bd-91-e5-90-8e-e7-ab-af-e5-9f-ba-e7-a1-80-e8-ae-be-e6-96-bd" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/02/e4-ba-92-e8-81-94-e7-bd-91-e5-90-8e-e7-ab-af-e5-9f-ba-e7-a1-80-e8-ae-be-e6-96-bd/" class="article-date">
  <time datetime="2016-09-02T15:11:45.000Z" itemprop="datePublished">2016-09-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/收藏/">收藏</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/02/e4-ba-92-e8-81-94-e7-bd-91-e5-90-8e-e7-ab-af-e5-9f-ba-e7-a1-80-e8-ae-be-e6-96-bd/">互联网后端基础设施</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>对于一个互联网企业，后端服务是必不可少的一个组成部分。抛开业务应用来说，往下的基础服务设施做到哪些才能够保证业务的稳定可靠、易维护、高可用呢？纵观整个互联网技术体系再结合公司的目前状况，个人认为必不可少或者非常关键的后端基础技术/设施如下图所示： <img src="http://mmbiz.qpic.cn/mmbiz_png/tzia4bcY5HEKxURwUfLYeg45dAmxqy7Shbj5emb9Gc72nkodx136sX4upPlctPoYZkg5WW1WGSsg2a8ic7aVopTQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<ul>
<li>Api网关</li>
<li>业务应用和后端基础框架</li>
<li>缓存、数据库、搜索引擎、消息队列</li>
<li>文件存储</li>
<li>统一认证中心</li>
<li>单点登录系统</li>
<li>统一配置中心</li>
<li>服务治理框架</li>
<li>统一调度中心</li>
<li>统一日志服务</li>
<li>数据基础设施</li>
<li>故障监控</li>
</ul>
<p>开发或者搭建好以上的后端基础设施，一般情况下是能够支撑很长一段时间内的业务的。</p>
<h2 id="Api网关"><a href="#Api网关" class="headerlink" title="Api网关"></a><strong>Api网关</strong></h2><p>在移动app的开发过程中，通常后端提供的接口需要以下功能的支持：</p>
<ul>
<li>负载均衡</li>
<li>api访问权限控制</li>
<li>用户鉴权</li>
</ul>
<p>一般的做法，使用nginx做负载均衡，然后在每个业务应用里做api接口的访问权限控制和用户鉴权，更优化一点的方式则是把后两者做成公共类库供所有业务调用。但从总体上来看，这三种特性都属于业务的公共需求，更可取的方式则是集成到一起作为一个服务，既可以动态地修改权限控制和鉴权机制，也可以减少每个业务集成这些机制的成本。这种服务就是Api网关(<a href="http://blog.csdn.net/pzxwhc/article/details/49873623)，可以选择自己实现，也可以使用开源软件实现，如Kong。如下图所示：" target="_blank" rel="noopener">http://blog.csdn.net/pzxwhc/article/details/49873623)，可以选择自己实现，也可以使用开源软件实现，如Kong。如下图所示：</a> <img src="http://mmbiz.qpic.cn/mmbiz_png/tzia4bcY5HEKxURwUfLYeg45dAmxqy7ShdgKpjcRJdZ2jYp6eQL3GxjpoZWEnyKrfy8Df8tt1DiaYUUmRppQp6dg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""> 但是以上方案的一个问题是由于所有api请求都要经过网关，它很容易成为系统的性能瓶颈。因此，可以采取的方案是：去掉api网关，让业务应用直接对接统一认证中心，在基础框架层面保证每个api调用都需要先通过统一认证中心的认证，这里可以采取缓存认证结果的方式避免对统一认证中心产生过大的请求压力。</p>
<h2 id="业务应用和后端基础框架"><a href="#业务应用和后端基础框架" class="headerlink" title="业务应用和后端基础框架"></a><strong>业务应用和后端基础框架</strong></h2><p>业务应用分为：在线业务应用和内部业务应用。</p>
<ul>
<li>在线业务应用：直接面向互联网用户的应用、接口等，典型的特点就是：请求量大、高并发、高可用、对故障的容忍度低。</li>
<li>内部业务应用：这个是面向公司内部的应用。比如，内部数据管理平台、广告投放平台等。相比起在线业务应用，其特点: 数据保密性高、压力小、并发量小、允许故障的发生。</li>
</ul>
<p>业务应用基于后端的基础框架开发，针对Java后端来说，应该有的几个框架如下：</p>
<ol>
<li>MVC框架：从十年前流行的Struts1、2到现在最为推崇的SpringMVC、Jersey以及国人开发的JFinal、阿里的WebX等等，这些框架尤其是后面流行的这些都是各有千秋的。选型的主要因素是看你的团队是否有一个对某框架能够做二次开发、定制的人在。很多时候，针对这些通用的框架，你是需要做一些特定的开发才能满足特定的需求的。比如，很多团队传递参数使用的都是UnderScore的命名法(下划线连接单词)，但是Java中确是使用LowCamel命名的。对于SpringMVC，可以通过注解的alias来指定，但这样需要对每一个参数都要指定alias有点效率太低，此外ModelAttribute也不支持别名，更好的方式是在框架层面统一对参数做Camel命名的转换达到目的。</li>
<li>IOC框架：ioc带来的好处无须多言。目前Java中最为流行的Spring自诞生就天然支持IOC。</li>
<li>ORM框架：MyBatis是目前最为流行的orm框架。此外，Spring ORM中提供的JdbcTemplate也很不错。当然，对于分库分表、主从分离这些需求，一般就需要实现自己的ORM框架来支持了，像阿里的tddl。此外，为了在服务层面统一解决分库分表、主从分离、主备切换、缓存、故障恢复等问题，很多公司都是有自己的数据库中间件的，比如阿里的Cobar、360的Atlas、网易的DDB、开源的MyCat等。</li>
<li>缓存框架：缓存框架主要指的是对redis、memcached这些缓存服务器的操作统一封装，一般使用Spring的RedisTemplate即可，也可以使用jedis做自己的封装，支持客户端分布式方案、主从等。</li>
<li>JavaEE应用性能检测框架：对于线上的JavaEE应用，需要有一个统一的框架集成到每一个业务中检测每一个请求、方法调用、jdbc连接、redis连接等的耗时、状态等。jwebap是一个可以使用的性能检测工具，但由于其已经很多年没有更新，有可能的话建议基于此项目做二次开发。</li>
</ol>
<p>一般来说，以上几个框架即可以完成一个后端应用的雏形。 对于这些框架来说，最为关键的是根据团队技术构成选择最合适的，有能力开发自己的框架则更好。此外，这里需要提供一个后端应用的模板或生成工具(如maven的archetype)给团队成员使用，可以让大家在开发新的应用的时候，迅速的生成雏形应用，而无需再做一些框架搭建的重复性劳动。</p>
<h2 id="缓存、数据库、搜索引擎、消息队列"><a href="#缓存、数据库、搜索引擎、消息队列" class="headerlink" title="缓存、数据库、搜索引擎、消息队列"></a><strong>缓存、数据库、搜索引擎、消息队列</strong></h2><p>缓存、数据库、搜索引擎、消息队列这四者都是应用依赖的后端基础服务，他们的性能直接影响到了应用的整体性能，有时候你代码写的再好也许就是因为这些服务导致应用性能无法提升上去。</p>
<h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a><strong>缓存</strong></h3><p>如缓存五分钟法则所讲：如果一个数据频繁被访问，那么就应该放内存中。这里的缓存就是一种读写效率都非常高的存储方案，能够应对高并发的访问请求，通常情况下也不需要持久化的保证。但相对其他存储来说，缓存一般是基于内存的，成本比较昂贵，因此不能滥用。 缓存可以分为：本地缓存和分布式缓存。</p>
<ul>
<li>本地缓存：主要指的是内存中的缓存机制。在Java中，Google Guava中就提供了本地缓存的实现机制。当然使用java的ConncurrentHashMap你也可以实现自己的本地缓存方案。</li>
<li>分布式缓存：指的单独的缓存服务。几年前比较流行的是memcached，但其只是一个KV的存储，支持的数据结构太少。现在最为流行的就是Redis，能够支持丰富的数据结构，基于事件驱动的单线程非阻塞IO也能够应对高并发的场景。集群方案除了官方的redis cluster, 目前比较流行的还有豌豆荚的codis、twitter的twemproxy。</li>
</ul>
<p>对于缓存的使用，需要注意以下几点：</p>
<ul>
<li>缓存的失效机制：当给某一个key设置了有效期，那么缓存何时对此key进行删除呢？一般来说会有以下几种方式：<ul>
<li>守护进程定时去扫描key，找到已经失效的key，然后删除</li>
<li>读取key的时候先去判断key是否失效，如果失效则删除并返回空。</li>
</ul>
</li>
<li>缓存的淘汰机制：是当缓存内存达到上限时如何删除缓存中的key。Redis提供了以下数据淘汰策略：</li>
<li>对于其具体的实现机制，可以参考《Redis设计与实现》一书<ul>
<li>volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰</li>
<li>volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰</li>
<li>volatile-random：从已设置过期时间的数据集中任意选择数据淘汰</li>
<li>allkeys-lru：从数据集中挑选最近最少使用的数据淘汰</li>
<li>allkeys-random：从数据集中任意选择数据淘汰</li>
<li>no-enviction（驱逐）：禁止驱逐数据</li>
</ul>
</li>
</ul>
<p>对于其具体的实现机制，可以参考《Redis设计与实现》一书</p>
<ul>
<li>缓存的更新机制: 通常来说有四种方式：Cache aside, Read through, Write through, Write behind caching，具体的可见陈皓大神的这篇总结：缓存更新的套路。</li>
<li>缓存的服务过载保护：缓存的服务过载指的是由于缓存失效，而引起后端服务的压力骤增，进一步产生雪崩效应。这个现象和缓存更新是相关的，采取何种策略在缓存失效的时候去更新缓存直接决定了服务过载的保护机制。通常的分为客户端和服务端的应对方案。前者的方案有：基于超时的简单模式、基于超时的常规模式、基于刷新的简单模式、基于刷新的常规模式、基于刷新的续费模式。后者的方案则是很常见的流量控制和服务降级。具体的可以看美团技术团队总结的这篇文章：Cache应用中的服务过载案例研究。</li>
</ul>
<h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a><strong>数据库</strong></h3><p>数据库是后端开发中非常常见的一个服务组件。对于数据库的选型，要根据业务的特点和数据结构的特点来决定。 从存储介质上，数据库可以分为：</p>
<ul>
<li>内存数据库： 数据主要存储在内存中，同时也可以采取措施对数据进行持久化到硬盘中。如Redis、H2DB的内存模式。对于这种数据库，由于内存成本昂贵，因此一定要做好存储的量化分析、容量预估，防止内存不足造成服务不可用。</li>
<li>硬盘数据库：数据存储在硬盘上的这种数据库是最为常见的。MySQL、Oracle、Postgresql、HBASE、H2DB、SqlLite等等都是硬盘数据库。此外，SSDB是基于SSD硬盘的KV数据库，支持的数据接口很丰富，是Redis的另外一个选择。</li>
</ul>
<p>从存储数据类型、数据模式上，数据库可以分为：</p>
<ul>
<li>关系型数据库：MySQL、Oracle、Postgresql都是关系型数据库的，是采用关系模型(关系模型指的就是二维表格模型，而一个关系型数据库就是由二维表及其之间的联系所组成的一个数据组织)来组织数据的数据库。</li>
<li>非关系型数据库：非关系型数据库是相对关系型数据库来讲的。以键值对存储，且结构不固定，每一个元组可以有不一样的字段，每个元组可以根据需要增加一些自己的键值对，这样就不会局限于固定的结构，可以减少一些时间和空间的开销。但是，其没有关系型数据库那种严格的数据模式，并不适合复杂的查询以及需要强事务管理的业务。非关系型数据库又可以分为：<ul>
<li>KV数据库：主要以(key,value)键值对存储数据的数据库。以Redis、RocksDB(levelDB)、SSDB为代表。</li>
<li>文档数据库：总体形式上也是键值对的形式，但是值里面又可以有各种数据结构：数组、键值对、字符串等等。以mongodb、couchdb为代表。</li>
<li>列数据库：也叫作稀疏大数据库，一般是用来存储海量数据的。相对于行数据库，这种数据库是以列为单位存储数据在介质上的。以Hbase、Cassendra为代表。</li>
</ul>
</li>
</ul>
<p>和数据库相关的一个很重要的就是数据库的索引。有一种说法是：“掌握了索引就等于掌握了数据库”。暂且不去评判此说法是否真的准确，但索引的确关系着数据库的读写性能。需要对数据库的索引原理做到足够的了解才能更好的使用各种数据库。通常来说，Mysql、Oracle、Mongodb这些都是使用的B树作为索引，是考虑到传统硬盘的特点后兼顾了读写性能以及范围查找需求的选择，而Hbase用得LSM则是为了提高写性能对读性能做了牺牲。</p>
<h3 id="搜索引擎"><a href="#搜索引擎" class="headerlink" title="搜索引擎"></a><strong>搜索引擎</strong></h3><p>搜索引擎也是后端应用中一个很关键的组件，尤其是对内容类、电商类的应用，通过关键词、关键字搜索内容、商品是一个很常见的用户场景。比较成熟的开源搜索引擎有Solr和Elasticsearch，很多中小型互联网公司搜索引擎都是基于这两个开源系统搭建的。它们都是基于Lucence来实现的，不同之处主要在于termIndex的存储、分布式架构的支持等等。 对于搜索引擎的使用，从系统熟悉、服务搭建、功能定制，需要花费较长时间。在这个过程中，需要注意以下问题：</p>
<ul>
<li>搜索引擎与公司现有数据系统的集成。现有的持久化、供搜索的数据的载体是什么, 如何让搜索引擎在全量和增量建索引过程中无缝集成原来的数据载体，才能发挥搜索引擎自身的实时性, 水平扩展性(性能与容量和机器数量成正比)等优势。</li>
<li>和数据库一样，对搜索引擎的索引机制也需要做到深入的了解。</li>
</ul>
<p>更为详细的对于搜索引擎的工程化实践可以参考有赞工程师的这篇文章：有赞搜索引擎实践(工程篇) 另外，搜索引擎还可以用在数据的多维分析上，就是GrowingIO、MixPanel中的可以任意维度查询数据报表的功能。当然，druid也许是一个更好的实现多维分析的方案，官方也有其与es的比较：<a href="http://druid.io/docs/latest/comparisons/druid-vs-elasticsearch.html。" target="_blank" rel="noopener">http://druid.io/docs/latest/comparisons/druid-vs-elasticsearch.html。</a></p>
<h3 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a><strong>消息队列</strong></h3><p>软件的组织结构，从开始的面向组件到SOA、SAAS是一个逐渐演变的过程。而到了今天微服务盛行的时代，你都不好意思说自己的系统只是单一的一个系统而没有解耦成一个个service。当然，小的系统的确没有拆分的必要性，但一个复杂的系统拆成一个个service做微服务架构确实是不得不做的事情。 那么问题就来了，service之间的通信如何来做呢？使用什么协议？通过什么方式调用？都是需要考虑的问题。 先抛开协议不谈，service之间的调用方式可以分为同步调用以及异步调用。同步调用的方式无需多说，那么异步调用是怎么进行的呢？一种很常见的方式就是使用消息队列，调用方把请求放到队列中即可返回，然后等待服务提供方去队列中去获取请求进行处理，然后把结果返回给调用方即可（可以通过回调）。 异步调用就是消息中间件一个非常常见的应用场景。此外，消息队列的应用场景还有以下：</p>
<ul>
<li>解耦：一个事务，只关心核心的流程，需要依赖其他系统但不那么重要的事情，有通知即可，无须等待结果。</li>
<li>最终一致性：指的是两个系统的状态保持一致，要么都成功，要么都失败，可以有一定的延迟，只要最终达到一致性即可。</li>
<li>广播：这是消息队列最基本的功能。生产者只需要发布消息，无须关心有哪些订阅者来消费消息。</li>
<li>错峰与流控：当上下游系统处理能力不同的时候就需要类似消息队列的方式做为缓冲区来隔开两个系统。</li>
</ul>
<p>目前主流的消息队列软件，主要有以下几种：</p>
<ul>
<li>ActiveMQ：Java中最为简单的消息队列，是对JMS的实现，没有规定消息的顺序、安全、重发等特性。</li>
<li>RabbitMQ：是对AMQP协议的实现，对于消息的顺序性、安全、重发等都做了很好的支持。比较适合不允许数据丢失、有事务需求的业务场景下的消息传输。</li>
<li>Kafka：是基于Log的消息队列，底层依赖于文件的顺序读取，是append-only的。适合对数据丢失不敏感、强调性能的一些海量日志传输场景中。是最近几年大数据领域很火的一个技术。</li>
<li>ZeroMQ：是一个网络编程的Pattern库，将常见的网络请求形式（分组管理，链接管理，发布订阅等）模式化、组件化，简而言之socket之上、MQ之下。对于MQ来说，网络传输只是它的一部分，更多需要处理的是消息存储、路由、Broker服务发现和查找、事务、消费模式（ack、重投等）、集群服务等。</li>
</ul>
<h2 id="文件存储"><a href="#文件存储" class="headerlink" title="文件存储"></a><strong>文件存储</strong></h2><p>不管是业务应用、依赖的后端服务还是其他的各种服务，最终还是要依赖于底层文件存储的。通常来说，文件存储需要满足的特性有：可靠性、容灾性、稳定性，即要保证存储的数据不会轻易丢失，即使发生故障也能够有回滚方案，也要保证高可用率。在底层可以采用传统的RAID作为解决方案，再上一层，目前hadoop的hdfs则是最为普遍的分布式文件存储方案，当然还有NFS、Samba这种共享文件系统也提供了简单的分布式存储的特性。 此外，如果文件存储确实成为了应用的瓶颈或者必须提高文件存储的性能从而提升整个系统的性能时，那么最为直接和简单的做法就是抛弃传统机械硬盘，用SSD硬盘替代。像现在很多公司在解决业务性能问题的时候，最终的关键点往往就是SSD。这也是用钱换取时间和人力成本最直接和最有效的方式。在数据库部分描述的SSDB就是对LevelDB封装之后，利用SSDB的特性的一种高性能KV数据库。 至于HDFS，如果要使用上面的数据，是需要通过hadoop的。类似xx on yarn的一些技术就是将非hadoop技术跑在hdfs上的解决方案(当然也是为了使用MR)。</p>
<h2 id="统一认证中心"><a href="#统一认证中心" class="headerlink" title="统一认证中心"></a><strong>统一认证中心</strong></h2><p>统一认证中心，主要是对app用户、内部用户、app等的认证服务，包括</p>
<ul>
<li>用户的注册、登录验证、token鉴权</li>
<li>内部信息系统用户的管理和登录鉴权</li>
<li>App的管理，包括app的secret生成，app信息的验证(如验证接口签名)等。</li>
</ul>
<p>之所以需要统一认证中心，就是为了能够集中对这些所有app都会用到的信息进行管理，也给所有应用提供统一的认证服务。尤其是在有很多业务需要共享用户数据的时候，构建一个统一认证中心是非常必要的。此外，通过统一认证中心构建移动app的单点登录也是水到渠成的事情(模仿web的机制，将认证后的信息加密存储到本地磁盘中供多个app使用)。</p>
<h2 id="单点登录系统"><a href="#单点登录系统" class="headerlink" title="单点登录系统"></a><strong>单点登录系统</strong></h2><p>目前很多大的在线web网站都是有单点登录系统的，通俗的来说就是只需要一次用户登录，就能够进入多个业务应用(权限可以不相同)，非常方便用户的操作。而在移动互联网公司中，内部的各种管理、信息系统同样也需要单点登录系统。目前，比较成熟的、用的最多的单点登录系统应该是耶鲁大学开源的CAS, 可以基于<a href="https://github.com/apereo/cas/tree/master/cas-server-webapp来定制开发的。此外，国人开源的kisso的这个也不错。基本上，单点登录的原理都类似下图所示：" target="_blank" rel="noopener">https://github.com/apereo/cas/tree/master/cas-server-webapp来定制开发的。此外，国人开源的kisso的这个也不错。基本上，单点登录的原理都类似下图所示：</a> <img src="http://mmbiz.qpic.cn/mmbiz_jpg/tzia4bcY5HEKxURwUfLYeg45dAmxqy7ShsfTeTkSibLmKFl8y1WSJdibeIE9RjMtJFjQRMiaBAsu4yEhic9DUKWNBoA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<h2 id="统一配置中心"><a href="#统一配置中心" class="headerlink" title="统一配置中心"></a><strong>统一配置中心</strong></h2><p>在Java后端应用中，一种读写配置比较通用的方式就是将配置文件写在propeties、yaml、HCON文件中，修改的时候只需要更新文件重新部署即可，可以做到不牵扯代码层面改动的目的。统一配置中心，则是基于这种方式之上的统一对所有业务或者基础后端服务的相关配置文件进行管理的统一服务, 具有以下特性：</p>
<ul>
<li>能够在线动态修改配置文件并生效</li>
<li>配置文件可以区分环境(开发、测试、生产等)</li>
<li>使用方便: 在java中可以通过注解、xml配置的方式引入相关配置</li>
</ul>
<p>disconf是可以在生产环境使用的一个方案，也可能根据自己的需求开发自己的配置中心(可以选择zookeeper作为配置存储)。</p>
<h2 id="服务治理框架"><a href="#服务治理框架" class="headerlink" title="服务治理框架"></a>服务治理框架</h2><p>对于外部API调用或者客户端对后端api的访问，可以使用http协议或者说restful(当然也可以直接通过最原始的socket来调用)。但对于内部服务间的调用，一般都是通过RPC机制来调用的。目前主流的RPC协议有：</p>
<ul>
<li>RMI</li>
<li>Hessian</li>
<li>Thrift</li>
<li>Dubbo</li>
</ul>
<p>这些RPC协议各有优劣点，需要针对业务需求做出相应的最好的选择。 这样，当你的系统服务在逐渐增多，RPC调用链越来越复杂，很多情况下，需要不停的更新文档来维护这些调用关系。一个对这些服务进行管理的框架可以大大节省因此带来的繁琐的人力工作。 传统的ESB(企业服务总线)本质就是一个服务治理方案，但esb作为一种proxy的角色存在于client和server之间，所有请求都需要经过esb，使得esb很容易成为性能瓶颈。因此，基于传统的esb，更好的一种设计如下图所示： <img src="http://mmbiz.qpic.cn/mmbiz_png/tzia4bcY5HEKxURwUfLYeg45dAmxqy7ShLibwnyMNTibibicXPhhMaaYvONtRBIUuUGSCbE88fX3aww0HsJCHmmtbSA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""> 如图，以配置中心为枢纽，调用关系只存在于client和提供服务的server之间，就避免了传统esb的性能瓶颈问题。对于这种设计，esb应该支持的特性如下：</p>
<ul>
<li>服务提供方的注册、管理</li>
<li>服务消费者的注册、管理</li>
<li>服务的版本管理、负载均衡、流量控制、服务降级等</li>
<li>服务的容错、熔断等</li>
</ul>
<p>阿里开源的dubbo则对以上做了很好的实现，也是目前很多公司都在使用的方案。但由于某些原因，dubbo现已不再维护，推荐大家使用当当后来维护的dubbox。</p>
<h2 id="统一调度中心"><a href="#统一调度中心" class="headerlink" title="统一调度中心"></a><strong>统一调度中心</strong></h2><p>在很多业务中，定时调度是一个非常普遍的场景，比如定时去抓取数据、定时刷新订单的状态等。通常的做法就是针对各自的业务依赖Linux的cron机制或者java中的quartz。统一调度中心则是对所有的调度任务进行管理，这样能够统一对调度集群进行调优、扩展、任务管理等。azkaban和oozie是hadoop的流式工作管理引擎，也可以作为统一调度中心来使用。当然，你也可以使用cron或者quartz来实现自己的统一调度中心。</p>
<ul>
<li>根据cron表达式调度任务</li>
<li>动态修改、停止、删除任务</li>
<li>支持任务工作流：比如一个任务完成之后再执行下一个任务</li>
<li>任务支持脚本、代码、url等多种形式</li>
<li>任务执行的日志记录、故障报警</li>
</ul>
<p>对于Java的quartz这里需要说明一下：这个quartz需要和spring quartz区分，后者是spring对quartz框架的简单实现也是目前使用的最多的一种调度方式。但是，其并没有做高可用集群的支持。而quartz虽然有集群的支持，但是配置起来非常复杂。现在很多方案都是使用zookeeper来实现spring quartz集群的。这里有一个国人开源的uncode-shcedule对此实现的还不错，可以根据自己的业务需求做二次开发。</p>
<h2 id="统一日志服务"><a href="#统一日志服务" class="headerlink" title="统一日志服务"></a><strong>统一日志服务</strong></h2><p>日志是开发过程必不可少的东西。有时候，打印日志的时机、技巧是很能体现出工程师编码水平的。毕竟，日志是线上服务能够定位、排查异常最为直接的信息。 通常的，将日志分散在各个业务中非常不方便对问题的管理和排查。统一日志服务则使用单独的日志服务器记录日志，各个业务通过统一的日志框架将日志输出到日志服务器上。 可以通过实现log4j后者logback的appender来实现统一日志框架，然后通过RPC调用将日志打印到日志服务器上。</p>
<h2 id="数据基础设施"><a href="#数据基础设施" class="headerlink" title="数据基础设施"></a><strong>数据基础设施</strong></h2><p>数据是最近几年非常火的一个领域。从《精益数据分析》到《增长黑客》，都是在强调数据的非凡作用。很多公司也都在通过数据推动产品设计、市场运营、研发等。详细的可见之前的一篇《数据杂谈》，对数据相关的东西做过一些总结。这里需要说明的一点是，只有当你的数据规模真的到了单机无法处理的规模才应该上大数据相关技术，千万不要为了大数据而大数据。很多情况下使用单机程序+mysql就能解决的问题非得上hadoop即浪费时间又浪费人力。</p>
<h3 id="数据高速公路"><a href="#数据高速公路" class="headerlink" title="数据高速公路"></a><strong>数据高速公路</strong></h3><p>接着上面讲的统一日志服务，其输出的日志最终是变成数据到数据高速公路上供后续的数据处理程序消费的。这中间的过程包括日志的收集、传输。 收集：统一日志服务将日志打印在日志服务上之后，需要日志收集机制将其集中起来。目前，常见的日志收集方案有：scribe、Chukwa、Kakfa和Flume。对比如下图所示： <img src="http://mmbiz.qpic.cn/mmbiz_png/tzia4bcY5HEKxURwUfLYeg45dAmxqy7Shd6TExZr5jicIopVtNRSZC4OBC9ztaCWzAucZUqpnSM0rsw9XOZhk4yA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""> 传输：通过消息队列将数据传输到数据处理服务中。对于日志来说，通常选择kafka这种消息队列即可。 此外，这里还有一个关键的技术就是数据库和数据仓库间的数据同步问题，即将需要分析的数据从数据库中同步到诸如hive这种数据仓库时使用的方案。比较简单的、用的也比较多的可以使用sqoop进行基于时间戳的数据同步，此外，阿里开源的canal实现了基于binlog增量同步，更加适合通用的同步场景，但是基于canal你还是需要做不少的业务开发工作的。推荐另一款国人开源的MySQL-Binlog，原理和canal类似，默认提供了任务的后台管理功能，只需要实现接收到binlog后的处理逻辑即可。</p>
<h3 id="离线数据分析"><a href="#离线数据分析" class="headerlink" title="离线数据分析"></a><strong>离线数据分析</strong></h3><p>离线数据分析是可以有延迟的，一般针对是非实时需求的数据分析工作，产生的也是T-1的报表。目前最常用的离线数据分析技术除了hadoop还有spark。相比hadoop，spark性能上有很大优势，当然对硬件资源要求也高。 对于hadoop，传统的MR编写很复杂，也不利于维护，可以选择使用hive来用sql替代编写mr，但是前提务必要对hive的原理做到了解。可以参见美团的这篇博文来学习:Hive SQL的编译过程。而对于spark，也有类似hive的spark sql。 此外，对于离线数据分析，还有一个很关键的就是数据倾斜问题。所谓数据倾斜指的是region数据分布不均，造成有的结点负载很低，而有些却负载很高，从而影响整体的性能。因此，处理好数据倾斜问题对于数据处理是很关键的。 对于hive的数据倾斜，可见:hive大数据倾斜总结。对于spark的倾斜问题，可见：Spark性能优化指南——高级篇。</p>
<h3 id="实时数据分析"><a href="#实时数据分析" class="headerlink" title="实时数据分析"></a><strong>实时数据分析</strong></h3><p>相对于离线数据分析，实时数据分析也叫在线数据分析，针对的是对数据有实时要求的业务场景，如广告结算、订单结算等。目前，比较成熟的实时技术有storm和spark streaming。相比起storm，spark streaming其实本质上还是基于批量计算的。如果是对延迟很敏感的场景，还是应该使用storm。 对于实时数据分析，需要注意的就是实时数据处理结果写入存储的时候，要考虑并发的问题，虽然对于storm的bolt程序来说不会有并发的问题，但是写入的存储介质是会面临多任务同时读写的。通常采用的方案就是采用时间窗口的方式对数据做缓冲后批量写入。 此外，实时数据处理一般情况下都是基于增量处理的，相对于离线来说并非可靠的，一旦出现故障(如集群崩溃)或者数据处理失败，是很难对数据恢复或者修复异常数据的。因此结合离线+实时是目前最普遍采用的数据处理方案。 Lambda架构就是一个结合离线和实时数据处理的架构方案。</p>
<h3 id="数据即席分析"><a href="#数据即席分析" class="headerlink" title="数据即席分析"></a><strong>数据即席分析</strong></h3><p>离线和实时数据分析产生的一些报表是给数据分析师、产品经理参考使用的，但是很多情况下，线上的程序并不能满足这些需求方的需求。这时候就需要需求方自己对数据仓库进行查询统计。针对这些需求方，SQL上手容易、易描述等特点决定了其可能是一个最为合适的方式。因此提供一个SQL的即席查询工具能够大大提高数据分析师、产品经理的工作效率。Presto、Impala、Hive都是这种工具。如果想进一步提供给需求方更加直观的ui操作界面，可以搭建内部的Hue。 <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAIAAACQd1PeAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyBpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBXaW5kb3dzIiB4bXBNTTpJbnN0YW5jZUlEPSJ4bXAuaWlkOkJDQzA1MTVGNkE2MjExRTRBRjEzODVCM0Q0NEVFMjFBIiB4bXBNTTpEb2N1bWVudElEPSJ4bXAuZGlkOkJDQzA1MTYwNkE2MjExRTRBRjEzODVCM0Q0NEVFMjFBIj4gPHhtcE1NOkRlcml2ZWRGcm9tIHN0UmVmOmluc3RhbmNlSUQ9InhtcC5paWQ6QkNDMDUxNUQ2QTYyMTFFNEFGMTM4NUIzRDQ0RUUyMUEiIHN0UmVmOmRvY3VtZW50SUQ9InhtcC5kaWQ6QkNDMDUxNUU2QTYyMTFFNEFGMTM4NUIzRDQ0RUUyMUEiLz4gPC9yZGY6RGVzY3JpcHRpb24+IDwvcmRmOlJERj4gPC94OnhtcG1ldGE+IDw/eHBhY2tldCBlbmQ9InIiPz6p+a6fAAAAD0lEQVR42mJ89/Y1QIABAAWXAsgVS/hWAAAAAElFTkSuQmCC" alt=""></p>
<h2 id="故障监控"><a href="#故障监控" class="headerlink" title="故障监控"></a><strong>故障监控</strong></h2><p>对于面向用户的线上服务，发生故障是一件很严重的事情。因此，做好线上服务的故障检测告警是一件非常重要的事情。可以将故障监控分为以下两个层面的监控：</p>
<ul>
<li>系统监控：主要指的对主机的带宽、cpu、内存、硬盘、io等硬件资源的监控。这可以使用开源的nagios、cacti等开源软件进行监控。目前，市面上也有很多第三方服务能够提供对于主机资源的监控，如监控宝等。对于分布式服务集群(如hadoop、storm、kafka、flume等集群)的监控则可以使用ganglia。</li>
<li>业务监控：是在主机资源层面以上的监控，比如app的pv、uv数据异常、交易失败等。需要业务中加入相关的监控代码，比如在异常抛出的地方，加一段日志记录。</li>
</ul>
<p>监控还有一个关键的步骤就是告警。告警的方式有很多种：邮件、im、短信等。考虑到故障的重要性不同、告警的合理性、便于定位问题等因素，有以下建议：</p>
<ul>
<li>告警日志要记录发生故障的机器id，尤其是在集群服务中，如果没有记录机器id，那么对于后续的问题定位会很困难。</li>
<li>要对告警做聚合，不要每一个故障都单独进行告警，这样会对工程师造成极大的困扰。</li>
<li>要对告警做等级划分，不能对所有告警都做同样的优先级处理。</li>
<li>使用微信做为告警软件，能够在节省短信成本的情况下，保证告警的到达率。</li>
</ul>
<p>故障告警之后，那么最最关键的就是应对了。对于创业公司来说，24小时待命是必备的素质，当遇到告警的时候，需要尽快对故障做出反应，找到问题所在，并能在可控时间内解决问题。对于故障问题的排查，基本上都是依赖于日志的。只要日志打的合理，一般情况下是能够很快定位到问题所在的，但是如果是分布式服务，并且日志数据量特别大的情况下，如何定位日志就成为了难题。这里有几个方案： 建立ELK(Elastic+Logstash+Kibana)日志集中分析平台，便于快速搜索、定位日志。对于ELK的介绍，可以见：使用Elasticsearch + Logstash + Kibana搭建日志集中分析平台实践 建立分布式请求追踪系统(也可以叫全链路监测系统)，对于分布式系统尤其是微服务架构，能够极大的方便在海量调用中快速定位并收集单个异常请求信息，也能快速定位一条请求链路的性能瓶颈。Google的Dapper、唯品会的Mercury、阿里的鹰眼、新浪的WatchMan都是类似的思路。此外，腾讯的染色日志机制本质上也是在链路追踪之上根据响应信息做了染色机制。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://linsheng9731.github.io/2016/09/02/e4-ba-92-e8-81-94-e7-bd-91-e5-90-8e-e7-ab-af-e5-9f-ba-e7-a1-80-e8-ae-be-e6-96-bd/" data-id="cjlyygoix000ef7vad86q3m3y" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-e5-ae-b9-e5-99-a8-e7-9a-84-e6-97-a5-e5-bf-97-e8-a7-a3-e5-86-b3-e6-96-b9-e6-a1-88" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/02/e5-ae-b9-e5-99-a8-e7-9a-84-e6-97-a5-e5-bf-97-e8-a7-a3-e5-86-b3-e6-96-b9-e6-a1-88/" class="article-date">
  <time datetime="2016-09-02T15:11:12.000Z" itemprop="datePublished">2016-09-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Docker/">Docker</a>►<a class="article-category-link" href="/categories/Docker/运维/">运维</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/02/e5-ae-b9-e5-99-a8-e7-9a-84-e6-97-a5-e5-bf-97-e8-a7-a3-e5-86-b3-e6-96-b9-e6-a1-88/">容器的日志解决方案</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>logspout</strong></p>
<p>git clone <a href="https://github.com/gliderlabs/logspout.git" target="_blank" rel="noopener">https://github.com/gliderlabs/logspout.git</a></p>
<p>在customer文件夹下的modules.go文件内添加以下代码：</p>
<p>[cc lang=”go”] package main</p>
<p>import ( _ “github.com/looplab/logspout-logstash” _ “github.com/gliderlabs/logspout/transports/udp” _ “github.com/gliderlabs/logspout/transports/tcp” ) [/cc]</p>
<p>打包成镜像：</p>
<p>[cc] docker build -t  my-logspout . [/cc]</p>
<p>多渠道转发：</p>
<p>[cc lang=”bash”] $ docker run \ –volume=/var/run/docker.sock:/var/run/docker.sock \ gliderlabs/logspout \ raw://192.168.10.10:5000?filter.name=<strong>db,syslog+tls://logs.papertrailapp.com:55555?filter.name=</strong>app [/cc]</p>
<p>上面的例子就是转发到两个渠道</p>
<p>重定向到logstash：</p>
<p>[cc lang]</p>
<p>docker run –name=”logspout”  -d \ –volume=/var/run/docker.sock:/var/run/docker.sock \ -e ROUTE_URIS=logstash+tcp://your-logstash-ip:5000 \ registry.growingio.com/growing-logspout [/cc]</p>
<p>配置你的logstash： [cc] input { udp { port  = 5000 codec = json } tcp { port  = 5000 codec =json } } [/cc]</p>
<p>一条有效的日志应该包含以下信息：</p>
<p>level：warnming，error，info，debug</p>
<p>code line ：哪个文件的第几行报错</p>
<p>application name：程序的名字</p>
<p>environment：test，staging，production</p>
<p>host name：机器名字</p>
<p>前三个可以配置log的格式，后两个可以通过收集程序来完成。</p>
<p>在启动logspout的时候还可以配置环境变量，用来跟踪不同的环境和机器：</p>
<p>[cc]</p>
<h1 id="Add-any-number-of-arbitrary-tags-to-your-event"><a href="#Add-any-number-of-arbitrary-tags-to-your-event" class="headerlink" title="Add any number of arbitrary tags to your event"></a>Add any number of arbitrary tags to your event</h1><p>-e LOGSTASH_TAGS=”docker,production” [/cc]</p>
<p>这样在logstash端收到的信息会想下面这样：</p>
<p>[cc] “tags”: [</p>
<p>“docker”,</p>
<p>“production”</p>
<p>], [/cc]</p>
<p>logstash 还允许用户定义一系列的filter，用以重新组织非结构化的日志数据。比如下面的例子，从日志中parse出了日志等级，时间，文件名，错误信息。</p>
<p>[cc] filter {</p>
<p>grok { match = { “message” =”%{DATA:Level}\ %{DATA:Date}\ %{DATA:Time}\ %{DATA:Filename}\ %{NUMBER:Line}\ %{DATA:message}” } } } [/cc]</p>
<p>原始信息：</p>
<p>[cc] [INFO] 2016-09-04 16:54:15.286 HttpDataRequestInvokerSupport.scala 88 from services.overview.handler.HttpMetricAggregateHandler in ForkJoinPool-4-worker-7 - Response from cache [/cc] 解析后的信息： [cc] { “message”:”[INFO] 2016-09-04 16:54:15.286 HttpDataRequestInvokerSupport.scala 88 from services.overview.handler.HttpMetricAggregateHandler in ForkJoinPool-4-worker-7 - Response from cache\r”, “@version”:”1”, “@timestamp”:”2016-09-04T09:58:58.996Z”, “host”:”127.0.0.1”, “port”:48529, “Level”:”[INFO]“, “Date”:”2016-09-04”, “Time”:”16:54:15.286”, “Filename”:”HttpDataRequestInvokerSupport.scala”, “Line”:”88” } [/cc]</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://linsheng9731.github.io/2016/09/02/e5-ae-b9-e5-99-a8-e7-9a-84-e6-97-a5-e5-bf-97-e8-a7-a3-e5-86-b3-e6-96-b9-e6-a1-88/" data-id="cjlyygoj0000if7vaqxzlyfgb" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-e9-9b-86-e7-be-a4-e8-a7-84-e6-a8-a1-e4-b8-8b-e6-97-a5-e5-bf-97-e5-a4-84-e7-90-86-e5-92-8c-e7-bd-91-e7-bb-9c-e6-96-b9-e6-a1-88" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/02/e9-9b-86-e7-be-a4-e8-a7-84-e6-a8-a1-e4-b8-8b-e6-97-a5-e5-bf-97-e5-a4-84-e7-90-86-e5-92-8c-e7-bd-91-e7-bb-9c-e6-96-b9-e6-a1-88/" class="article-date">
  <time datetime="2016-09-02T13:11:00.000Z" itemprop="datePublished">2016-09-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/收藏/">收藏</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/02/e9-9b-86-e7-be-a4-e8-a7-84-e6-a8-a1-e4-b8-8b-e6-97-a5-e5-bf-97-e5-a4-84-e7-90-86-e5-92-8c-e7-bd-91-e7-bb-9c-e6-96-b9-e6-a1-88/">集群规模下日志处理和网络方案</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在早期 Docker 实现中，日志这块的功能都不完善，所有容器内的标准输出和错误都会写入到/var/lib/docker/containers/{$cid}/{$cid}-log.json中。因为没有日志自动分卷以及容器绑定，所以一旦到线上就会出现瞬间磁盘打满的情况。而这个文件同时又是 docker logs api 的 data source，加之 docker 1.6 引入的 log-driver 参数，因此对于线上日志的收集管理我们目前有这么几个方法。</p>
<ol>
<li><strong>监控文件，并通过管道转出数据</strong>。这种方案最大的问题是日志文件和容器是绑定的，因此需要有一个 agent 的角色来做这件事，变相的增加了开发成本，还要考虑管道的可靠性问题。另外 CentOS 6系和7系日志地址不一样，如果硬编码则扩展性不佳，如果读取系统配置，那就要考虑跨系统之间的路径问题。</li>
<li><strong>通过**</strong>docker logs api<strong>**来远程重定向日志</strong>。这种方法最大的问题是你避免不了还是得有 agent 去清理日志这么个操作，否则的话磁盘依然会被打满，当然也可以配合 logrotate 来做这事，不过增加了运维成本。如果是远端调用这个 API 的话，需要考虑连接的可靠性，一旦出现重连，那就要做日志回溯，否则会丢失一部分日志。</li>
<li><strong>容器内进程自己写出日志</strong>。这又有两种方案，如下：<ul>
<li>进程直接写出，控制权交给了业务方，对业务不透明，可控性降低，毕竟是集群环境。这样一来也要暴露集群结构给上层。</li>
<li>映射日志设备（/dev/log）进容器，容器内进程直接写设备，隔离性减弱，单点问题追踪会很麻烦，因为这时候 stdout 和 stderr 是没有内容的，也就是docker log命令无任何输出。</li>
</ul>
</li>
</ol>
<p>『进程直接写出』这种方案我们试过，不过要让业务方来改代码，所以整体推进很难了。另外它还暴露了远端日志服务器地址，无论是网络上还是安全上都是有问题的。举个例子，一旦介入 SDN 等管理网络的方式，那么等于就是破坏了整体的隔离性。『映射日志设备进容器』这种方案就是定位问题容器比较麻烦，而且还是要涉及到跟业务方沟通。</p>
<ol>
<li><strong>使用新版的 log-driver 参数</strong>，其中包含支持 syslog，看似很美好，但是在集群环境下要考虑 syslog 单点问题。一般来说会有多个 syslog 或者支持 syslog 协议的远端 server （logstash）。如果使用远程 syslog 接受日志，大量容器日志输出并不平均，从而会产生性能热点和流量热点。如果走单机 syslog 再汇总，那就和上面的方案『进程直接输出』没多大区别了，同样是跟踪问题比较麻烦。我觉得目前这个实现更多的是方便了之前使用 syslog 方案的。</li>
<li><strong>通过attach 方法截获容器输出流重定向</strong>。这种方案需要 agent 支持，有一定开发要求。目前我们采用的就是这种方案，通过一个模块实现了 consistent hash，然后把日志流量打到远端收集服务器上。这个方案只需要让业务把日志输出到 stdout/stderr 中即可，并不会增加开发成本。同时Docker 1.6中可以指定日志驱动为 none，避免了 logs 文件的产生。另外一方面可以把容器自己的 meta info 附加到日志流里面，从而实现远端的日志检索分类聚合等操作。但这个方案最大的问题是开发力量的投入，不同的 dockeclient 实现质量也不一样，当然好处也是很明显的，灵活可控，日志流向和分配都在自己受伤。</li>
</ol>
<p>所以日志方面，从目前 Docker 实现来看，如果开发力量跟得上，agent + attach 方案是灵活性和可控性是最高的。目前 log-driver 对于上规模的集群来说还是不太好用，理想状态下我希望是可以指定多个 log-drivers，通过 hash 方案打到远端。当然具体方案的选取就得看各自公司本身的基础设施和设计目标了。</p>
<p>说完日志来说下网络，目前 Docker 的网络方案主要有这么几个，当然现在大家都在等 1.7，不过我认为对于生产系统而言，已有 SDN 方案的不会太过于在乎 Libnetwork，可能会研究下其和 Docker 是怎样通过 plugin 方式结合的。因为其他它案目前都是 Hook 方式去做的。</p>
<ol>
<li>默认 NAT/BR/HOST，NAT 有性能损失，BR 有网络闪断，HOST 流控不好做，端口冲突靠业务保证没法做到透明。</li>
<li>网络层方案</li>
<li>a. <strong>隧道方案</strong></li>
<li>I. <strong>OVS</strong>，主要是有性能方面的损失，基于 VxLAN 和 GRE 协议，类似的方案还有 Kubernetes/Socketplane 的实现。</li>
<li>II. <strong>Weave</strong>，UDP 广播，本机建立新的 BR，通过 PCAP 互通。</li>
<li>III. <strong>Flannel</strong>，UDP 广播，VxLan。</li>
<li><p>隧道方案非常灵活，但是因为太过于灵活，出了网络问题（A-B 链路抖动）跟踪起来比较麻烦，大规模集群情况下这是需要考虑的一个点，毕竟即便是内网也不一定风平浪静。</p>
</li>
<li><p>b. <strong>路由方案</strong></p>
</li>
<li>I. <strong>Pipework</strong>，对于 Docker BR 本身的扩展，当然也支持 OVS macvlan 等方案的结合。现在 libnetwork 出来变相的是废了这个项目了，长远来看后继无人，因此它不是一个很好的选择。</li>
<li>II. <strong>Calico</strong>，基于 BGP 协议的路由方案，支持很细致的 ACL 控制，对于隔离要求比较严格的场景比较适合，对混合云亲和度比较高，因为它不涉及到二层的支持。</li>
<li>III. <strong>Macvlan</strong>，从逻辑和 Kernel 层来看隔离性和性能最优的方案，基于二层隔离，所以需要二层路由器支持，大多数云服务商不支持，所以混合云上比较难以实现。</li>
</ol>
<p>路由方案没那么灵活，大多数情况下需要有一个 agent 在容器主机上去操作，一般是从 3 层或者 2 层实现隔离和跨主机容器互通的，出了问题也很容易排查。但是路由方案对本身物理网络依赖会比隧道方案要重。另外 hook 的话毕竟还是不太优美，所以得看看 libnetwork 是怎样和 Docker 结合的。</p>
<p>目前<strong>我们选取的是 macvlan 的方案实现的二层隔离</strong>，说轻点主要是对容器而言，可以完全当容器为一台虚拟机。说重点，是因为其对物理网络基础设施依赖程度最高。</p>
<p>Q&amp;A</p>
<p><strong>问题：macvlan 是怎么做的？</strong></p>
<p><strong>答案：</strong> Linux 内核支持，直接用 agent 在 host 上生成设备塞入到容器的 namespace 中。</p>
<p><strong>问题：为何不直接打日志？</strong></p>
<p><strong>答案：</strong> 容器内的话得考虑 docker 本身存储性能问题，如果是容器外得考虑卷管理问问题，如果是远端，得考虑和业务结合的问题。</p>
<p><strong>问题：网络层比较成熟的选择？</strong></p>
<p><strong>答案：</strong> macvlan 进了内核，Calico 做了十来年了，这2者都会比较成熟，weave 比较简单和方便。</p>
<p><strong>问题：日志丢失问题</strong></p>
<p><strong>答案：</strong> 尽可能的不让业务层去控制日志输出，即便是 socket 文件或者设备都有可能被删除从而导致日志丢失，因此尽量从平台层面控制。</p>
<p><strong>问题：二进制服务跑在 Docker 里面的问题</strong></p>
<p><strong>答案：</strong> 目前我们也在做类似的事情，跑Redis。但是因为容器本身没有 init 进程，因此内核参数都是默认的，有些 binary 应用在这方面会比较敏感。我们目前也没找到比较优美的方法解决。Docker 官方仓库有不少类似的 issue。</p>
<p>＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝</p>
<p>以上内容根据2015年5月5日晚微信群分享内容整理。<strong>分享人彭哲夫，芒果TV平台部核心技术团队负责人，主要负责Docker和Redis Cluster相关的技术设施开发。之前担任过豆瓣App Engine和金山快盘的主程。在系统工程方面有非常丰富的经验。</strong>接下来，DockOne每周都会组织定向的技术分享，欢迎感兴趣的同学加我微信（liyingjiesx）参与。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://linsheng9731.github.io/2016/09/02/e9-9b-86-e7-be-a4-e8-a7-84-e6-a8-a1-e4-b8-8b-e6-97-a5-e5-bf-97-e5-a4-84-e7-90-86-e5-92-8c-e7-bd-91-e7-bb-9c-e6-96-b9-e6-a1-88/" data-id="cjlyygoj7000uf7vay70jt3qy" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-e6-97-a5-e5-bf-97-e7-b3-bb-e7-bb-9f-e8-b0-83-e7-a0-94" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/02/e6-97-a5-e5-bf-97-e7-b3-bb-e7-bb-9f-e8-b0-83-e7-a0-94/" class="article-date">
  <time datetime="2016-09-02T13:09:06.000Z" itemprop="datePublished">2016-09-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Web/">Web</a>►<a class="article-category-link" href="/categories/Web/技术积累/">技术积累</a>►<a class="article-category-link" href="/categories/Web/技术积累/运维/">运维</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/02/e6-97-a5-e5-bf-97-e7-b3-bb-e7-bb-9f-e8-b0-83-e7-a0-94/">日志系统调研</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>一般而言，日志系统主要有一下几方面的职责：收集日志信息，提供查询接口，统计并友好的显示。就以上几点而言，ELK技术栈很好的满足的需求，elasticsearch的搜索检索功能对于普通的日志分析绰绰有余，Kibana的图形化显示也直观。而在日志收集这块则有很多选择，不仅仅是ELK里的logstash，还有最近比较火的fluentd，他们的作用就是将各个来源的日志信息的差异进行统一的归一处理。</p>
<p><strong>LogStash</strong></p>
<p>1、定义： 时间+事件=日志；</p>
<p>2、客户端用ruby实现，依赖JRuby等，嵌入了elasticsearch,形成logstash-1.2.2-flatjar.jar 大约20M的包，个人而言很不喜欢这种方式，在生产环境中是不会把存储和搜集放到一个地方的，但官方却加入了es且你不能修改配置。</p>
<p>3、体系架构：        </p>
<p>可以看出这是典型的：<strong>数据源+Broker+存储+webUI</strong>，这套体系非常灵活从数据采集到数据输出都可以自定义，尤其是后端的Search 使用ES，ES这个搜索引擎鼎鼎大名，我非常喜欢他查询DSL，呵呵。</p>
<p><img src="http://images.cnitblog.com/blog/87097/201311/25141900-5f0c718825444f27ab1398f013adf5ac.jpg" alt=""></p>
<p>4、input ，output配置：</p>
<p><img src="http://images.cnitblog.com/blog/87097/201311/25143723-92a5c57b89a7427a94bca6616208a06b.jpg" alt=""> </p>
<p>这是个最简单的日志监控了，结果输出到es中，当然也可以输出到redis中，这里的输出位置可以配置是个很讨人喜欢的功能；其input的type是ES的存储索引表，这个可以自定义，其他filter也是可以配置的这样可以只收集需要的信息，非常灵活。</p>
<p>5、ES 存储:</p>
<p>这里存储也是可以配置的，我配置为3个片，2个副本，其实日志属于内部使用，访问量很小，所以可以节约点用存储成本，从上面可以看出索引名是系统自动生成的好处是很明显一天一个日志类别，不好的是如果我想某个域下的日志放到一起，是不能自定义的。</p>
<p>可以看出其日志搜集是一行一行读取的，如果你在记事本写一大块日志信息而存储到ES中，可能回出现多行日志的错觉，这个不是很重要</p>
<p><img src="http://images.cnitblog.com/blog/87097/201311/25145124-29ed43f6df66488095d6b71609e4f137.jpg" alt=""></p>
<p><img src="http://images.cnitblog.com/blog/87097/201311/25151621-560be683037b435c80ec75ecbefd09df.jpg" alt=""></p>
<p>6、web UI:</p>
<p>logstash 1.2.2版本使用了全新的webUI 大致是htm5+JS构成，这样可以搭建个独立web Ui 而不必像之前的版本那样”粘“在一起。这个UI和splunk UI有点类似，但其功能远没有splunk UI丰富</p>
<p>7、事件预警：</p>
<pre><code>logstash 可以执行script，exec程序达到预警的作用（本人没有使用这个功能）
</code></pre><p>8、外部接口：</p>
<pre><code>ES REST风格接口非常强大，完全可以定制化
</code></pre><p>基于上面几个方面的对比，logstash 这套系统，配置灵活，天生融入ES引擎，webUI 就我个人来说其体验不好，单调繁琐，可能以后的版本的会改进吧。如果你有时间完全可以使用其数据源服务，后端存储使用ES，WEbUI 自己写</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://linsheng9731.github.io/2016/09/02/e6-97-a5-e5-bf-97-e7-b3-bb-e7-bb-9f-e8-b0-83-e7-a0-94/" data-id="cjlyygoj4000pf7vae7wwxwrc" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/5/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Ansible/">Ansible</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Ansible/工具/">工具</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Ansible/工具/技术积累/">技术积累</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Ansible/工具/技术积累/运维/">运维</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Ansible/工具/运维/">运维</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/BlockChain/">BlockChain</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/BlockChain/技术积累/">技术积累</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/Marathon/">Marathon</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/Marathon/工具/">工具</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/Marathon/工具/技术积累/">技术积累</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/运维/">运维</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Golang/">Golang</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Golang/运维/">运维</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Marathon/">Marathon</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Marathon/技术积累/">技术积累</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Marathon/技术积累/运维/">运维</a></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Scala/">Scala</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Scala/Web/">Web</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Scala/Web/技术积累/">技术积累</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Scala/Web/技术积累/未分类/">未分类</a></li></ul></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Web/">Web</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Web/技术积累/">技术积累</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Web/技术积累/运维/">运维</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Web/运维/">运维</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术积累/">技术积累</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/收藏/">收藏</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/未分类/">未分类</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/运维/">运维</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ansible/">Ansible</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Marathon/">Marathon</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Scala/">Scala</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Web/">Web</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blockchain/">blockchain</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/golang/">golang</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rchain/">rchain</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据/">大数据</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/容器/">容器</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/技术文档/">技术文档</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Ansible/" style="font-size: 12px;">Ansible</a> <a href="/tags/Marathon/" style="font-size: 16px;">Marathon</a> <a href="/tags/Scala/" style="font-size: 18px;">Scala</a> <a href="/tags/Web/" style="font-size: 16px;">Web</a> <a href="/tags/blockchain/" style="font-size: 20px;">blockchain</a> <a href="/tags/golang/" style="font-size: 12px;">golang</a> <a href="/tags/rchain/" style="font-size: 10px;">rchain</a> <a href="/tags/大数据/" style="font-size: 18px;">大数据</a> <a href="/tags/容器/" style="font-size: 10px;">容器</a> <a href="/tags/技术文档/" style="font-size: 14px;">技术文档</a> <a href="/tags/机器学习/" style="font-size: 10px;">机器学习</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">February 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/09/12/Spark-潜规则/">Spark 潜规则</a>
          </li>
        
          <li>
            <a href="/2018/06/11/yi-tai-fang-ri-zhi/">以太坊日志</a>
          </li>
        
          <li>
            <a href="/2018/04/28/kubernetes-kuai-su-shang-shou/">Kubernetes 快速上手</a>
          </li>
        
          <li>
            <a href="/2018/04/25/rchain-jian-zao-zheng-que-de-gong-shi-xie-yi/">Rchain 建造正确的共识协议</a>
          </li>
        
          <li>
            <a href="/2018/04/23/yi-tai-fang-xiang-guan-mi-ma-xue-suan-fa/">以太坊相关密码学算法</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Damon Lin<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>